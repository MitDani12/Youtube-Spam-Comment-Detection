{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9902d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f2ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = {\n",
    "    \"Psy\": \"9bZkp7q19f0\",\n",
    "    \"KatyPerry\": \"CevxZvSJLk8\",\n",
    "    \"LMFAO\": \"KQ6zr6kCPj8\",\n",
    "    \"Eminem\": \"uelHwf8o7_U\",\n",
    "    \"Shakira\": \"pRpeEdMmmQ0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9901520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_comments_20120117.csv\n"
     ]
    }
   ],
   "source": [
    "all_comments = pd.DataFrame()\n",
    "for filename in os.listdir(\"media\"):\n",
    "    artist = filename.split(\".\")[0].split(\"-\")[-1]\n",
    "    if artist not in videos:\n",
    "        print(filename)\n",
    "        continue\n",
    "    else:\n",
    "        video_id = videos[artist]\n",
    "    df = pd.read_csv(f\"media/{filename}\")\n",
    "    all_comments = pd.concat([all_comments, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9348fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"media/youtube_comments_20120117.csv\", header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ca8552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c24ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"COMMENT_ID\", \"VIDEO_ID\", \"AUTHOR\", \"CONTENT\", \"CLASS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff2f248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_comments = all_comments[[\"CONTENT\", \"CLASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "394c5192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6282629</th>\n",
       "      <td>The video wouldn't have been that bad but the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452731</th>\n",
       "      <td>can't wait.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714917</th>\n",
       "      <td>damn Wiese lost...﻿ LETS FLIP A CAR!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410018</th>\n",
       "      <td>what is this a parody﻿ of?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912058</th>\n",
       "      <td>piano music﻿ bits are from treyarch zombies?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   CONTENT  CLASS\n",
       "6282629  The video wouldn't have been that bad but the ...      0\n",
       "1452731                                      can't wait.\\n      0\n",
       "5714917               damn Wiese lost...﻿ LETS FLIP A CAR!      0\n",
       "3410018                         what is this a parody﻿ of?      0\n",
       "2912058       piano music﻿ bits are from treyarch zombies?      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.concat([df[[\"CONTENT\", \"CLASS\"]], all_comments[[\"CONTENT\", \"CLASS\"]]])\n",
    "comments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aabf543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\AppData\\Local\\Temp\\ipykernel_2220\\3008190459.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sm_comments.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1760, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sm_comments.shape)\n",
    "sm_comments.drop_duplicates(inplace=True)\n",
    "sm_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831830e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6057689, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6057689, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(comments.shape)\n",
    "comments.drop_duplicates(inplace=True)\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4b0cd",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c8bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_url(text):\n",
    "    return bool(re.search(r'((https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b|watch\\?v)', text))\n",
    "\n",
    "def starts_with_punc(text):\n",
    "    text = text.strip()\n",
    "    start_char = text[0]\n",
    "    i = 1\n",
    "    while i < len(text):\n",
    "        if text[i] == start_char:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    return start_char in punctuation and i > 2\n",
    "\n",
    "def all_caps(text):\n",
    "    return text.strip().isupper()\n",
    "\n",
    "def clean(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\\\n', ' ', text)\n",
    "    text = ''.join(c for c in text if c not in punctuation)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df345da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16daf8e5c2e547d89863d52aaa025500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6057689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123b6677d03c4809894c334051446d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\AppData\\Local\\Temp\\ipykernel_2220\\3572047756.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sm_comments[\"HAS_URL\"] = sm_comments.CONTENT.progress_apply(has_url).astype(int)\n"
     ]
    }
   ],
   "source": [
    "comments[\"HAS_URL\"] = comments.CONTENT.progress_apply(has_url).astype(int)\n",
    "sm_comments[\"HAS_URL\"] = sm_comments.CONTENT.progress_apply(has_url).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65e33250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75732cf6c7a24a46aa244b4396203179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6057689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6cba1e3180472c99555987b7a90010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\AppData\\Local\\Temp\\ipykernel_2220\\2018745244.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sm_comments[\"CAPS\"] = sm_comments.CONTENT.progress_apply(all_caps).astype(int)\n"
     ]
    }
   ],
   "source": [
    "comments[\"CAPS\"] = comments.CONTENT.progress_apply(all_caps).astype(int)\n",
    "sm_comments[\"CAPS\"] = sm_comments.CONTENT.progress_apply(all_caps).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd500eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c52db0ee9d4e7981fdcdf54a1ec15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6057689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b2fa1b2f13432295957e3d08e857de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\AppData\\Local\\Temp\\ipykernel_2220\\1331524508.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sm_comments[\"PUNC\"] = sm_comments.CONTENT.progress_apply(starts_with_punc).astype(int)\n"
     ]
    }
   ],
   "source": [
    "comments[\"PUNC\"] = comments.CONTENT.progress_apply(starts_with_punc).astype(int)\n",
    "sm_comments[\"PUNC\"] = sm_comments.CONTENT.progress_apply(starts_with_punc).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b355df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98ea65148fc48ffb7d56434eb7059a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6057689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be1976be3c1438681a6c7ac1e7ab5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\AppData\\Local\\Temp\\ipykernel_2220\\2303216252.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sm_comments[\"CLEAN_CONTENT\"] = sm_comments.CONTENT.progress_apply(clean)\n"
     ]
    }
   ],
   "source": [
    "comments[\"CLEAN_CONTENT\"] = comments.CONTENT.progress_apply(clean)\n",
    "sm_comments[\"CLEAN_CONTENT\"] = sm_comments.CONTENT.progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5616d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>HAS_URL</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>CLEAN_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4396425</th>\n",
       "      <td>You guys realize this is a bud light commercial.﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you guys realize this is a bud light commercial﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>ele falou , próxima semana , ai cortaram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ele falou  próxima semana  ai cortaram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697217</th>\n",
       "      <td>My favourite literal so far﻿ =)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>my favourite literal so far﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353387</th>\n",
       "      <td>\"I can see it in your eyes that you really wan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i can see it in your eyes that you really want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272948</th>\n",
       "      <td>more﻿ skyblock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more﻿ skyblock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031408</th>\n",
       "      <td>@user1556274 \\nXbox\\npc have so many bugs you ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xbox pc have so many bugs you have to fix yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148464</th>\n",
       "      <td>I'd really like that copy =)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>id really like that copy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831517</th>\n",
       "      <td>i like to barrel roll on fridays</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i like to barrel roll on fridays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204303</th>\n",
       "      <td>His eye is yellow... Did you get beat up? :(</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>his eye is yellow did you get beat up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532232</th>\n",
       "      <td>@user384421 its Gerudoku 32x﻿ Textures</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>its gerudoku x﻿ textures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   CONTENT  CLASS  HAS_URL  \\\n",
       "4396425  You guys realize this is a bud light commercial.﻿      0        0   \n",
       "9164              ele falou , próxima semana , ai cortaram      0        0   \n",
       "4697217                    My favourite literal so far﻿ =)      0        0   \n",
       "5353387  \"I can see it in your eyes that you really wan...      0        0   \n",
       "5272948                                     more﻿ skyblock      0        0   \n",
       "3031408  @user1556274 \\nXbox\\npc have so many bugs you ...      0        0   \n",
       "148464                        I'd really like that copy =)      0        0   \n",
       "1831517                   i like to barrel roll on fridays      0        0   \n",
       "2204303       His eye is yellow... Did you get beat up? :(      0        0   \n",
       "5532232             @user384421 its Gerudoku 32x﻿ Textures      0        0   \n",
       "\n",
       "         CAPS  PUNC                                      CLEAN_CONTENT  \n",
       "4396425     0     0   you guys realize this is a bud light commercial﻿  \n",
       "9164        0     0             ele falou  próxima semana  ai cortaram  \n",
       "4697217     0     0                      my favourite literal so far﻿   \n",
       "5353387     0     0  i can see it in your eyes that you really want...  \n",
       "5272948     0     0                                     more﻿ skyblock  \n",
       "3031408     0     0    xbox pc have so many bugs you have to fix yo...  \n",
       "148464      0     0                          id really like that copy   \n",
       "1831517     0     0                   i like to barrel roll on fridays  \n",
       "2204303     0     0             his eye is yellow did you get beat up   \n",
       "5532232     0     0                           its gerudoku x﻿ textures  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a47142a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>HAS_URL</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>CLEAN_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How To Make A Lot Of Money Fast</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how to make a lot of money fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>I loved, she is amazing.. OMG your eyes*_*﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i loved she is amazing omg your eyes﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>music yeah﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>music yeah﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Have you tried a new social network TSU? This ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>have you tried a new social network tsu this n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I dont even watch it anymore i just come here ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i dont even watch it anymore i just come here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>please subscribe to my page. thanks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please subscribe to my page thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Thumbs up if shrek is gay 👍﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thumbs up if shrek is gay 👍﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Shakira is different :) She is so happy all th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shakira is different  she is so happy all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>the best!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Thumbs up if you listen this in 2015.﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thumbs up if you listen this in ﻿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT  CLASS  HAS_URL  CAPS  \\\n",
       "189                    How To Make A Lot Of Money Fast      1        0     0   \n",
       "68         I loved, she is amazing.. OMG your eyes*_*﻿      0        0     0   \n",
       "86                                         music yeah﻿      0        0     0   \n",
       "190  Have you tried a new social network TSU? This ...      1        1     0   \n",
       "28   I dont even watch it anymore i just come here ...      0        0     0   \n",
       "317               please subscribe to my page. thanks.      1        0     0   \n",
       "126                       Thumbs up if shrek is gay 👍﻿      1        0     0   \n",
       "127  Shakira is different :) She is so happy all th...      0        0     0   \n",
       "287                                          the best!      0        0     0   \n",
       "346             Thumbs up if you listen this in 2015.﻿      0        0     0   \n",
       "\n",
       "     PUNC                                      CLEAN_CONTENT  \n",
       "189     0                    how to make a lot of money fast  \n",
       "68      0              i loved she is amazing omg your eyes﻿  \n",
       "86      0                                        music yeah﻿  \n",
       "190     0  have you tried a new social network tsu this n...  \n",
       "28      0  i dont even watch it anymore i just come here ...  \n",
       "317     0                 please subscribe to my page thanks  \n",
       "126     0                       thumbs up if shrek is gay 👍﻿  \n",
       "127     0  shakira is different  she is so happy all the ...  \n",
       "287     0                                           the best  \n",
       "346     0                  thumbs up if you listen this in ﻿  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e4e6858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6038868, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments = comments[comments.CLEAN_CONTENT.str.strip().str.len() > 1]\n",
    "clean_comments = clean_comments[~clean_comments.CLEAN_CONTENT.isna()]\n",
    "clean_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b2650e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1729, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_clean_comments = sm_comments[sm_comments.CLEAN_CONTENT.str.strip().str.len() > 1]\n",
    "sm_clean_comments = sm_clean_comments[~sm_clean_comments.CLEAN_CONTENT.isna()]\n",
    "sm_clean_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1204c3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>HAS_URL</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>CLEAN_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009658</th>\n",
       "      <td>@user146516 An absolute yes to both of the que...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an absolute yes to both of the questions shes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966442</th>\n",
       "      <td>@user591317 8==D﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708378</th>\n",
       "      <td>Also, take gay out of it, literally: a (GAY) p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>also take gay out of it literally a gay person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922516</th>\n",
       "      <td>YOUR ONLY SUPPOSE TO BLOW THE BLOODY DOORS OFF!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>your only suppose to blow the bloody doors off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826531</th>\n",
       "      <td>هههههههههههههأأأي  الله يسعدك دنيا واخره يابو ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>هههههههههههههأأأي الله يسعدك دنيا واخره يابو م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700978</th>\n",
       "      <td>@user885333 im﻿ going for you</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>im﻿ going for you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712063</th>\n",
       "      <td>Hola Megan, soy de España y me encanta como ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hola megan soy de españa y me encanta como can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069127</th>\n",
       "      <td>@user704253 WTF BITCH SHE NOT FUCKING KESHA GO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wtf bitch she not fucking kesha go fix your e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124485</th>\n",
       "      <td>how i met your﻿ mother!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how i met your﻿ mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591327</th>\n",
       "      <td>I can't believe I﻿ just watched a video on peo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i cant believe i﻿ just watched a video on peop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   CONTENT  CLASS  HAS_URL  \\\n",
       "2009658  @user146516 An absolute yes to both of the que...      0        0   \n",
       "5966442                                  @user591317 8==D﻿      0        0   \n",
       "1708378  Also, take gay out of it, literally: a (GAY) p...      0        0   \n",
       "922516     YOUR ONLY SUPPOSE TO BLOW THE BLOODY DOORS OFF!      0        0   \n",
       "2826531  هههههههههههههأأأي  الله يسعدك دنيا واخره يابو ...      0        0   \n",
       "3700978                      @user885333 im﻿ going for you      0        0   \n",
       "712063   Hola Megan, soy de España y me encanta como ca...      0        0   \n",
       "1069127  @user704253 WTF BITCH SHE NOT FUCKING KESHA GO...      0        0   \n",
       "4124485                            how i met your﻿ mother!      0        0   \n",
       "3591327  I can't believe I﻿ just watched a video on peo...      0        0   \n",
       "\n",
       "         CAPS  PUNC                                      CLEAN_CONTENT  \n",
       "2009658     0     0   an absolute yes to both of the questions shes...  \n",
       "5966442     0     0                                                 d﻿  \n",
       "1708378     0     0  also take gay out of it literally a gay person...  \n",
       "922516      1     0     your only suppose to blow the bloody doors off  \n",
       "2826531     0     0  هههههههههههههأأأي الله يسعدك دنيا واخره يابو م...  \n",
       "3700978     0     0                                  im﻿ going for you  \n",
       "712063      0     0  hola megan soy de españa y me encanta como can...  \n",
       "1069127     0     0   wtf bitch she not fucking kesha go fix your e...  \n",
       "4124485     0     0                             how i met your﻿ mother  \n",
       "3591327     0     0  i cant believe i﻿ just watched a video on peop...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments.reset_index(drop=True, inplace=True)\n",
    "clean_comments.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e9b5032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>HAS_URL</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>PUNC</th>\n",
       "      <th>CLEAN_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Most viewed video on youtube...daaaaaaaaaaannn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>most viewed video on youtubedaaaaaaaaaaannng t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Please visit this Website: oldchat.tk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please visit this website oldchattk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>I hope everyone is in good spirits I&amp;#39;m a h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i hope everyone is in good spirits im a hard w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Shakira﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shakira﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>It is a shit﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it is a shit﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Subscribe me Secret videos :D﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>subscribe me secret videos d﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>❤️❤️❤️﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>❤️❤️❤️﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>&lt;a href=\"https://m.freemyapps.com/share/url/10...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a hrefa﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>I love this-the talents of eminem and Skylar,w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i love thisthe talents of eminem and skylarwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Thumbs up if you&amp;#39;re watching in 2015﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thumbs up if youre watching in ﻿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT  CLASS  HAS_URL  CAPS  \\\n",
       "268   Most viewed video on youtube...daaaaaaaaaaannn...      0        0     0   \n",
       "1591              Please visit this Website: oldchat.tk      1        0     0   \n",
       "1290  I hope everyone is in good spirits I&#39;m a h...      1        0     0   \n",
       "1509                                           Shakira﻿      0        0     0   \n",
       "457                                       It is a shit﻿      0        0     0   \n",
       "1050                     Subscribe me Secret videos :D﻿      1        0     0   \n",
       "1363                                            ❤️❤️❤️﻿      0        0     0   \n",
       "931   <a href=\"https://m.freemyapps.com/share/url/10...      1        1     0   \n",
       "1227  I love this-the talents of eminem and Skylar,w...      0        0     0   \n",
       "829           Thumbs up if you&#39;re watching in 2015﻿      0        0     0   \n",
       "\n",
       "      PUNC                                      CLEAN_CONTENT  \n",
       "268      0  most viewed video on youtubedaaaaaaaaaaannng t...  \n",
       "1591     0                please visit this website oldchattk  \n",
       "1290     0  i hope everyone is in good spirits im a hard w...  \n",
       "1509     0                                           shakira﻿  \n",
       "457      0                                      it is a shit﻿  \n",
       "1050     0                      subscribe me secret videos d﻿  \n",
       "1363     0                                            ❤️❤️❤️﻿  \n",
       "931      0                                           a hrefa﻿  \n",
       "1227     0  i love thisthe talents of eminem and skylarwor...  \n",
       "829      0                   thumbs up if youre watching in ﻿  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_clean_comments.reset_index(drop=True, inplace=True)\n",
    "sm_clean_comments.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2aa41",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "007d2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Cleaned Data to Save Cleaning Time\n",
    "clean_comments.to_csv('clean_comments.csv', index=False)\n",
    "sm_clean_comments.to_csv('sm_clean_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467257b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comments = pd.read_csv('clean_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc7a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05548423976149172, 0.9445157602385083)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for imbalance in dataset\n",
    "spam_comments = clean_comments[clean_comments.CLASS == 1]\n",
    "ham_comments = clean_comments[clean_comments.CLASS == 0]\n",
    "spam_comments.shape[0]/clean_comments.shape[0], ham_comments.shape[0]/clean_comments.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66bb8ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Comment URL %: 4.12431132148677\n",
      "Ham Comment URL %: 0.35911109178678235\n",
      "Spam Comment all uppercase words %: 5.517486315965404\n",
      "Ham Comment all uppercase words %: 4.262417059766759\n",
      "Spam Comment that begin with punctuations %: 0.584667912207293\n",
      "Ham Comment that begin with punctuations %: 0.17430466604228825\n"
     ]
    }
   ],
   "source": [
    "# Percentage of comments with urls\n",
    "print(\"Spam Comment URL %:\", spam_comments.HAS_URL.sum()/spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment URL %:\", ham_comments.HAS_URL.sum()/ham_comments.shape[0]*100)\n",
    "# Percentage of comments with all uppercase words\n",
    "print(\"Spam Comment all uppercase words %:\", spam_comments.CAPS.sum()/spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment all uppercase words %:\", ham_comments.CAPS.sum()/ham_comments.shape[0]*100)\n",
    "# Percentage of comments that begin with punctuations\n",
    "print(\"Spam Comment that begin with punctuations %:\", spam_comments.PUNC.sum()/spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment that begin with punctuations %:\", ham_comments.PUNC.sum()/ham_comments.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533304e8",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bea2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_clean_comments = pd.read_csv('sm_clean_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc07dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47137073452862926, 0.5286292654713707)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for imbalance in dataset\n",
    "sm_spam_comments = sm_clean_comments[sm_clean_comments.CLASS == 1]\n",
    "sm_ham_comments = sm_clean_comments[sm_clean_comments.CLASS == 0]\n",
    "sm_spam_comments.shape[0]/sm_clean_comments.shape[0], sm_ham_comments.shape[0]/sm_clean_comments.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670a14a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Comment URL %: 21.595092024539877\n",
      "Ham Comment URL %: 0.87527352297593\n",
      "Spam Comment all uppercase words %: 5.521472392638037\n",
      "Ham Comment all uppercase words %: 5.470459518599562\n",
      "Spam Comment that begin with punctuations %: 0.6134969325153374\n",
      "Ham Comment that begin with punctuations %: 0.10940919037199125\n"
     ]
    }
   ],
   "source": [
    "# Percentage of comments with urls\n",
    "print(\"Spam Comment URL %:\", sm_spam_comments.HAS_URL.sum()/sm_spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment URL %:\", sm_ham_comments.HAS_URL.sum()/sm_ham_comments.shape[0]*100)\n",
    "# Percentage of comments with all uppercase words\n",
    "print(\"Spam Comment all uppercase words %:\", sm_spam_comments.CAPS.sum()/sm_spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment all uppercase words %:\", sm_ham_comments.CAPS.sum()/sm_ham_comments.shape[0]*100)\n",
    "# Percentage of comments that begin with punctuations\n",
    "print(\"Spam Comment that begin with punctuations %:\", sm_spam_comments.PUNC.sum()/sm_spam_comments.shape[0]*100)\n",
    "print(\"Ham Comment that begin with punctuations %:\", sm_ham_comments.PUNC.sum()/sm_ham_comments.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503586d7",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8eb7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm_clean_comments[[\"CONTENT\"]]\n",
    "y = sm_clean_comments[['CLASS']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ddb3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train[\"CONTENT\"])\n",
    "X_test_tfidf = vectorizer.transform(X_test[\"CONTENT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d919d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Nearest Neighbors\n",
      "Score: 0.6647398843930635\n",
      "Model: Linear SVM\n",
      "Score: 0.6069364161849711\n",
      "Model: RBF SVM\n",
      "Score: 0.9479768786127167\n",
      "Model: Decision Tree\n",
      "Score: 0.8988439306358381\n",
      "Model: Random Forest\n",
      "Score: 0.6994219653179191\n",
      "Model: Neural Net\n",
      "Score: 0.9508670520231214\n",
      "Model: AdaBoost\n",
      "Score: 0.9190751445086706\n",
      "Model: Naive Bayes\n",
      "Score: 0.8179190751445087\n",
      "Model: QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agyey\\miniconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6734104046242775\n",
      "Model: Multinomial NB\n",
      "Score: 0.9335260115606936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"Multinomial NB\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    MultinomialNB(),\n",
    "]\n",
    "\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(f\"Model: {name}\")\n",
    "    try:\n",
    "        clf.fit(X_train_tfidf, y_train.CLASS)\n",
    "        score = clf.score(X_test_tfidf, y_test.CLASS)\n",
    "    except:\n",
    "        clf.fit(X_train_tfidf.toarray(), y_train.CLASS)\n",
    "        score = clf.score(X_test_tfidf.toarray(), y_test.CLASS)\n",
    "    print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad4a7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62638644\n",
      "Validation score: 0.892086\n",
      "Iteration 2, loss = 0.38017041\n",
      "Validation score: 0.899281\n",
      "Iteration 3, loss = 0.19453473\n",
      "Validation score: 0.906475\n",
      "Iteration 4, loss = 0.11637790\n",
      "Validation score: 0.928058\n",
      "Iteration 5, loss = 0.08091238\n",
      "Validation score: 0.920863\n",
      "Iteration 6, loss = 0.06184985\n",
      "Validation score: 0.928058\n",
      "Iteration 7, loss = 0.04945354\n",
      "Validation score: 0.935252\n",
      "Iteration 8, loss = 0.04166619\n",
      "Validation score: 0.935252\n",
      "Iteration 9, loss = 0.03668759\n",
      "Validation score: 0.942446\n",
      "Iteration 10, loss = 0.03291888\n",
      "Validation score: 0.928058\n",
      "Iteration 11, loss = 0.03027196\n",
      "Validation score: 0.920863\n",
      "Iteration 12, loss = 0.02819092\n",
      "Validation score: 0.920863\n",
      "Iteration 13, loss = 0.02631595\n",
      "Validation score: 0.920863\n",
      "Iteration 14, loss = 0.02500090\n",
      "Validation score: 0.920863\n",
      "Iteration 15, loss = 0.02396628\n",
      "Validation score: 0.920863\n",
      "Iteration 16, loss = 0.02317418\n",
      "Validation score: 0.920863\n",
      "Iteration 17, loss = 0.02249708\n",
      "Validation score: 0.920863\n",
      "Iteration 18, loss = 0.02225345\n",
      "Validation score: 0.920863\n",
      "Iteration 19, loss = 0.02109836\n",
      "Validation score: 0.920863\n",
      "Iteration 20, loss = 0.02079621\n",
      "Validation score: 0.920863\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "CPU times: total: 2min 57s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = MLPClassifier(alpha=0.001, max_iter=1000, hidden_layer_sizes=(100, 100,), batch_size=16, early_stopping=True, verbose=True)\n",
    "model.fit(X_train_tfidf, y_train.CLASS)\n",
    "predictions = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38cb7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168  10]\n",
      " [ 10 158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       178\n",
      "           1       0.94      0.94      0.94       168\n",
      "\n",
      "    accuracy                           0.94       346\n",
      "   macro avg       0.94      0.94      0.94       346\n",
      "weighted avg       0.94      0.94      0.94       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b49ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_comments[[\"CONTENT\"]]\n",
    "y = clean_comments[['CLASS']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a9505",
   "metadata": {},
   "source": [
    "## AS-IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train[\"CONTENT\"])\n",
    "X_test_tfidf = vectorizer.transform(X_test[\"CONTENT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "18d43449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.6 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SGDClassifier(alpha=.1, loss='perceptron', n_jobs=-1, random_state=0)\n",
    "model.fit(X_train_tfidf, y_train.CLASS)\n",
    "predictions = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1545f78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1100962   43503]\n",
      " [  45355   21718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96   1144465\n",
      "           1       0.33      0.32      0.33     67073\n",
      "\n",
      "    accuracy                           0.93   1211538\n",
      "   macro avg       0.65      0.64      0.64   1211538\n",
      "weighted avg       0.93      0.93      0.93   1211538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9b90d",
   "metadata": {},
   "source": [
    "## Class Balanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8cf4e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24.7 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SGDClassifier(alpha=.1, loss='perceptron', n_jobs=-1, random_state=0, class_weight=\"balanced\")\n",
    "model.fit(X_train_tfidf, y_train.CLASS)\n",
    "predictions = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bb69cf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[821834 322631]\n",
      " [ 25125  41948]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83   1144465\n",
      "           1       0.12      0.63      0.19     67073\n",
      "\n",
      "    accuracy                           0.71   1211538\n",
      "   macro avg       0.54      0.67      0.51   1211538\n",
      "weighted avg       0.92      0.71      0.79   1211538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6780d3c8",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X.values.reshape(-1, 1), y.values.reshape(-1))\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size=0.2)\n",
    "X_train_over = X_train_over.reshape(-1)\n",
    "X_test_over = X_test_over.reshape(-1)\n",
    "X_train_over_tfidf = vectorizer.fit_transform(X_train_over)\n",
    "X_test_over_tfidf = vectorizer.transform(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = SGDClassifier(alpha=.1, loss='perceptron', n_jobs=-1, random_state=0)\n",
    "model.fit(X_train_over_tfidf, y_train_over)\n",
    "predictions = model.predict(X_test_over_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1df64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_over, predictions))\n",
    "print(classification_report(y_test_over, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8be7f3",
   "metadata": {},
   "source": [
    "## Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a2d0e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler()\n",
    "X_under, y_under = undersample.fit_resample(X.values.reshape(-1, 1), y.values.reshape(-1))\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.2)\n",
    "X_train_under = X_train_under.reshape(-1)\n",
    "X_test_under = X_test_under.reshape(-1)\n",
    "X_train_under_tfidf = vectorizer.fit_transform(X_train_under)\n",
    "X_test_under_tfidf = vectorizer.transform(X_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c80853c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.33 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SGDClassifier(alpha=.1, loss='perceptron', n_jobs=-1, random_state=0)\n",
    "model.fit(X_train_under_tfidf, y_train_under)\n",
    "predictions = model.predict(X_test_under_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cffbd56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68     67400\n",
      "           1       0.67      0.65      0.66     66776\n",
      "\n",
      "    accuracy                           0.67    134176\n",
      "   macro avg       0.67      0.67      0.67    134176\n",
      "weighted avg       0.67      0.67      0.67    134176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test_under, predictions)\n",
    "print(classification_report(y_test_under, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc80aa",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "38342357",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_over\n",
    "y_train = y_train_over\n",
    "X_test = X_test_over\n",
    "y_test = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1ca1a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 1, 'tfidf__max_df': 0.5, 'tfidf__min_df': 1}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier(loss='perceptron', n_jobs=-1, random_state=0)\n",
    "params = {\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'tfidf__max_df': [0.5, 0.95],\n",
    "    'model__alpha': [0.1, 1, 10],\n",
    "}\n",
    "best_params = search_para(X_train, y_train, model=model, params=params)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d7368536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 266 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_df = best_params[\"tfidf__max_df\"]\n",
    "min_df = best_params[\"tfidf__min_df\"]\n",
    "vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf=True, max_df=max_df, min_df=min_df)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "35003b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = best_params[\"model__alpha\"]\n",
    "model = SGDClassifier(alpha=alpha, loss='perceptron', n_jobs=-1, random_state=0)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "224c6a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[178  10]\n",
      " [ 20 183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       188\n",
      "           1       0.95      0.90      0.92       203\n",
      "\n",
      "    accuracy                           0.92       391\n",
      "   macro avg       0.92      0.92      0.92       391\n",
      "weighted avg       0.92      0.92      0.92       391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_over, predictions))\n",
    "print(classification_report(y_test_over, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ca9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
